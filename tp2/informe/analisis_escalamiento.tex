\section{Testing: Analisis de escalamiento}
\subsection{Race conditions y Leaks de memoria}
El servidor multi fue testeado para ambas cosas con las herramientas \verb|valgrind --leak-check=full| y \verb|valgrind --tool=helgrind| y se intent\'o realizar una prueba con \verb|thread-sanitizer| de \verb|clang|, pero debido a problemas de instalaci\'on de \verb|clang/compilacion| en \verb|x86|/\verb|x64| no se logr\'o realizar los tests a tiempo.

\subsection{Testing: Analisis de escalabilidad}
A priori existe una cantidad de clientes $k \in \mathbb{N}$ tal que el servidor comienza a tener una ejecucion poco viable, lease consume mucha memoria ram, debido a la creacion excesiva de nuevos hilos, este valor es dificil de determinar dado que si queremos asegurar buen funcionamiento, debemos correr el servidor con valgrind para chequear leaks de memoria y problemas de pthreads y esto produce mucho overhead en el uso de ram del proceso del servidor sobre valgrind, pero a partir de un numero aproximado de 175 clientes concurrentes comienza a haber problemas de conexion, errores de \verb|colabuf| de la biblioteca proporcionada y de lectura-escritura en los sockets. 

\subsubsection{Respecto a cambios en el hardware y la arquitectura fisica del sistema}
Hasta cierto punto, puede ser viable agregar mas memoria ram y tener un servidor totalmente dedicado a atender clientes. El calculo de la RAM asignada al servidor debe hacerse con una estimacion aproximada del peor caso acerca de la carga total del servidor (cantidad de clientes simultaneos + 1), dado que este sera el numero maximo de hilos que puede manejar, habria que calcular en peor caso, cuanta memoria RAM utiliza cada thread(tienen entre otras cosas, pila y registros unicos por thread) y cuanta memoria ram usa el thread principal y el overhead del sistema operativo y la creacion del proceso que encapsula todos los threads.
A partir de que esta solucion no mejore, se puede recurrir a sistemas distribuidos que balanceen la carga de forma mas uniforme y permitan el escalamiento a la cantidad de clientes requerida, un ejemplo seria asignar una porcion de la matriz a cada estacion de trabajo.

\subsubsection{Respecto al software}
Al utilizar threads y no procesos(hijos creados con fork, por ejemplo), se gana en performance dado que el fork es bastante mas costoso que un pthread\_create. Asimismo los cambios de contexto tiene un overhead mucho menor en threads respecto a procesos, aproximadamente de un orden de magnitud teorico. Fueron utilizados en principio por netscape navigator y tuvieron exito dada la ganancia en performance mencionada anteriormente. Como desventaja, todos los threads comparten los mismos datos y es necesario tomar recaudos para la correcta sincronizacion entre ellos. Otro problema es que cualquier libreria que se use debe ser thread-safe.
Como eleccion para maximizar el rendimiento y minimizar el consumo es buena la eleccion de threads sobre procesos como mencionamos anteriormente, pero ademas otra medida podria ser minimizar el uso de variables de stack en los threads, dado que esto aparentemente disminuiria muy poco, pero hay que multiplicarlo por la cantidad de hilos corriendo, puede ser una mejora significativa. Servidores Web como Apache utilizan threads, ver aqui \url{http://httpd.apache.org/docs/2.2/mod/worker.html}, una idea que podriamos tomar de ahi, es hacer uso de un \verb|pool| de threads libres, los cuales sean asignados cuando se registra un pedido, evitando el overhead de la creacion del thread, y reponiendo en el \verb|pool| otro hilo concurrentemente. 